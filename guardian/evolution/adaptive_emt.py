"""
Adaptive Evolutionary Mutation Testing (EMT) Engine

Self-improving mutation testing with evolutionary algorithms and 
multi-objective optimization for test suite enhancement.
"""

import numpy as np
import logging
from typing import List, Dict, Any, Tuple, Optional
import random
import time
import os
import ast
from pathlib import Path # Added
from concurrent.futures import ThreadPoolExecutor, as_completed

from .types import EvolutionHistory, TestIndividual
from .smart_mutator import SmartMutator
from .operators import CrossoverOperator, MutationOperator
from .fitness import FitnessEvaluator, MultiObjectiveFitness, FitnessVector
from ..budget import Budget # Added
from ..utils.pid_controller import PIDController # Added
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel
from sklearn.linear_model import LinearRegression
from scipy.stats import norm # Added for EI calculation


logger = logging.getLogger(__name__)


class AdaptiveEMT:
    """
    Adaptive Evolutionary Mutation Testing Engine
    
    Uses evolutionary algorithms to evolve test suites that maximize
    mutation killing effectiveness while maintaining quality.
    Now incorporates budget awareness and PID control for dynamic parameter tuning.
    """
    
    def __init__(self,
                 code_root: Path, # Changed from codebase_path (str)
                 existing_tests: List[Path], # New parameter
                 fitness_evaluator: FitnessEvaluator, # New: pass instance
                 budget: Budget, # New parameter
                 pid: PIDController, # New parameter
                 focus_modules: Optional[List[str]] = None, # New parameter
                 # Default values for rates, can be overridden or adapted
                 mutation_rate: float = 0.1, 
                 crossover_rate: float = 0.7,
                 early_stopping_patience: int = 5 # Kept for internal stagnation check
                ):
        self.code_root = code_root
        self.existing_tests_paths = existing_tests # Store paths to initial tests
        self.focus_modules = focus_modules
        self.fitness_evaluator = fitness_evaluator # Use passed instance
        self.budget = budget
        self.pid = pid
        
        self.early_stopping_patience = early_stopping_patience
        
        # Initialize components that are internally managed or configured
        # SmartMutator now uses code_root
        self.smart_mutator = SmartMutator(str(code_root)) 
        self.crossover = CrossoverOperator()
        self.mutation_op = MutationOperator()
        self.mo_fitness = MultiObjectiveFitness()
        
        # Evolution state
        self.population: List[TestIndividual] = []
        self.history = EvolutionHistory() # Will be re-initialized in evolve
        self.current_generation_num = 0 # Renamed from self.current_generation
        
        # Adaptive parameters & operators related params
        self.base_mutation_rate = mutation_rate
        self.current_mutation_rate = self.base_mutation_rate
        self.crossover_rate = crossover_rate
        self.stagnation_counter = 0
        self.best_hypervolume_ever = -float('inf')
        self.current_mutants: List[Dict[str, Any]] = []
        self.current_delta_m: float = 0.0 # Placeholder for achieved delta_m

        # Metrics for PID control and budget tracking
        self.cpu_used_total_min: float = 0.0
        self.wall_time_start: Optional[float] = None
        self.all_project_mutants: List[Dict[str, Any]] = [] # To store all generated mutants for the project
        self.hardest_mutants_cache: List[Dict[str, Any]] = [] # Cache for the current set of hardest mutants

        # GP Model components for Multi-Fidelity Optimization
        self.gp_model_delta: Optional[GaussianProcessRegressor] = None
        self.gp_rho: float = 0.5  # Initial estimate for rho, mean of Beta(2,2)
        
        # Data for GP training:
        # Store (individual_features, f1_score, f2_score) for individuals evaluated at both fidelities
        self.multi_fidelity_training_data: List[Tuple[np.ndarray, float, float]] = []
        # Kernel for the GP on delta
        self.gp_kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)) + WhiteKernel(0.1, (1e-10, 1e1))


    def get_hardest_mutants(self, count: int = 100) -> List[Dict[str, Any]]:
        """
        Identifies a subset of "hardest" mutants for low-fidelity evaluation.
        Placeholder implementation for now.
        
        Prioritization should be:
        1. Mutants that survived previous full runs (requires history).
        2. Mutants generated by specific complex operators.
        3. A random subset if no prior data or not enough from above.
        
        Args:
            count: The desired number of hard mutants.

        Returns:
            A list of mutant dictionaries.
        """
        logger.info(f"Attempting to get {count} hardest mutants (placeholder implementation).")
        # For now, if we have project mutants, take a sample. Otherwise, dummy.
        if self.all_project_mutants:
            if len(self.all_project_mutants) <= count:
                return self.all_project_mutants
            return random.sample(self.all_project_mutants, count)
        
        # Dummy data if no project mutants loaded yet
        dummy_mutants = [
            {"id": f"hard_mut_{i}", "file_path": "some/file.py", "line_number": 10+i,
             "original_code_snippet": "a + b", "mutated_code_snippet": "a - b",
             "status": "survived", "operator_type": "MATH_REPLACEMENT"}
            for i in range(min(count, 5)) # Return fewer if count is small
        ]
        logger.warning("Returning dummy 'hardest mutants' as no project mutants were loaded/generated yet.")
        self.hardest_mutants_cache = dummy_mutants # Cache them
        return dummy_mutants

    def _evaluate_low_fidelity(self, individual: TestIndividual) -> FitnessVector:
        """
        Evaluates an individual against a small set of "hardest" mutants.
        Placeholder: Calls the main fitness evaluator with a subset of mutants.
        """
        if not self.hardest_mutants_cache:
            logger.warning("No 'hardest mutants' available for low-fidelity evaluation. Using empty set.")
            # Fallback or error, for now, evaluate against empty set (will yield poor/default fitness)
            # return self.fitness_evaluator.evaluate_individual(individual, [])
            # FitnessEvaluator might not take mutants directly, it might run them.
            # This needs alignment with FitnessEvaluator's interface.
            # For now, return a default/dummy fitness vector.
            return FitnessVector(mutation_score=0.0, test_count=1.0, execution_time=0.1, behavioral_coverage=0.0)


        logger.debug(f"Low-fidelity evaluation for individual (gen {individual.generation}) against {len(self.hardest_mutants_cache)} hardest mutants.")
        # Assuming self.fitness_evaluator.evaluate_individual can take a 'mutants_to_run' list.
        # This is a simplification; the actual FitnessEvaluator might need more context or
        # to run mutmut itself with a specific config targeting these mutants.
        # For M0 of Phase 2, this is a conceptual placeholder.
        # fitness_vector = self.fitness_evaluator.evaluate_individual(individual, self.hardest_mutants_cache)
        
        # Placeholder fitness calculation for low-fidelity
        # Simulate some score based on how many dummy "hard" mutants it might kill
        killed_count = 0
        if "assert 1 ==" in individual.test_code: # Super simple heuristic
            killed_count = random.randint(0, min(5, len(self.hardest_mutants_cache)))
        
        sim_mutation_score = killed_count / len(self.hardest_mutants_cache) if self.hardest_mutants_cache else 0.0
        
        return FitnessVector(
            mutation_score=sim_mutation_score,
            test_count=1.0, # Assuming single test
            execution_time=random.uniform(0.01, 0.1), # Simulate fast execution
            behavioral_coverage=random.uniform(0.0, 0.2) # Lower behavior coverage expected
        )

    def _evaluate_high_fidelity(self, individual: TestIndividual) -> FitnessVector:
        """
        Evaluates an individual against the full set of project mutants.
        Placeholder: Calls the main fitness evaluator with all mutants.
        """
        logger.debug(f"High-fidelity evaluation for individual (gen {individual.generation}) against {len(self.all_project_mutants)} total mutants.")
        # fitness_vector = self.fitness_evaluator.evaluate_individual(individual, self.all_project_mutants)
        
        # Placeholder fitness calculation for high-fidelity
        killed_count = 0
        if "assert 1 ==" in individual.test_code or "assert add(" in individual.test_code : # Slightly better heuristic
            killed_count = random.randint(0, min(20, len(self.all_project_mutants)))
        
        sim_mutation_score = killed_count / len(self.all_project_mutants) if self.all_project_mutants else 0.0

        return FitnessVector(
            mutation_score=sim_mutation_score,
            test_count=1.0,
            execution_time=random.uniform(0.05, 0.5), # Simulate slightly longer execution
            behavioral_coverage=random.uniform(0.1, 0.5)
        )


    def _initialize_population(self) -> None: # Removed test_suite_path, uses self.existing_tests_paths
        """
        Initializes the population by parsing existing test files.
        If `focus_modules` are provided, it might prioritize or filter tests.
        If not enough tests are found, random ones might be generated (placeholder).
        The population size for initialization will be guided by an initial PID output
        or a lookup table value before the main evolve loop starts.
        """
        logger.info(f"Initializing population from {len(self.existing_tests_paths)} existing test paths.")
        parsed_individuals = []

        # Determine initial population size (e.g., from PID or lookup table)
        # For M0, let's assume a small fixed initial pop if PID isn't used for *first* pop_size
        # Or, the caller of evolve could provide an initial pop_size.
        # For now, _initialize_population will just parse what's given.
        # The evolve loop will manage the target size per generation.

        for filepath in self.existing_tests_paths:
            if not filepath.is_file() or not filepath.name.startswith("test_") or not filepath.name.endswith(".py"):
                logger.warning(f"Skipping non-test file or invalid path: {filepath}")
                continue
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()
                tree = ast.parse(content, filename=str(filepath))
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef) and node.name.startswith("test_"):
                        test_code = ast.get_source_segment(content, node)
                        if test_code is None:
                            logger.warning(f"Could not extract source for {node.name} in {filepath}")
                            continue
                        
                        assertions = [] # Simplified parsing for now
                        for sub_node in ast.walk(node):
                            if isinstance(sub_node, ast.Assert):
                                assertion_code = ast.get_source_segment(content, sub_node)
                                assertions.append({
                                    "type": "assert",
                                    "code": assertion_code if assertion_code else "Unknown assertion",
                                    "target_criticality": 1.0 
                                })
                        individual = TestIndividual(
                            test_code=test_code,
                            assertions=assertions,
                            generation=0 
                        )
                        parsed_individuals.append(individual)
            except Exception as e:
                logger.error(f"Error parsing test file {filepath}: {e}")
        
        self.population = parsed_individuals
        logger.info(f"Parsed {len(self.population)} individuals from existing tests.")

        # Placeholder: If focus_modules are defined, could filter/prioritize individuals
        # Placeholder: If population is too small after parsing, generate/mutate to fill
        # For M0, we'll work with what's parsed. The evolve loop will handle size.


    def _simulate_generation_cost(self, pop_size: int) -> Tuple[float, float]:
        """
        Simulates CPU and wall time cost for running one generation.
        For M0 testing purposes.

        Args:
            pop_size (int): Current population size.

        Returns:
            Tuple[float, float]: Simulated CPU cost (minutes), Wall cost (minutes)
        """
        # Simple simulation: cost increases with population size
        # Assume 1 pop_size unit = 0.05 CPU core-minutes and 0.02 wall-minutes
        cpu_cost = pop_size * 0.05 
        wall_cost = pop_size * 0.02
        # Add some base cost
        cpu_cost += 0.1 
        wall_cost += 0.05
        logger.debug(f"Simulated cost for pop_size {pop_size}: CPU {cpu_cost:.2f}m, Wall {wall_cost:.2f}m")
        return cpu_cost, wall_cost

    def _run_one_generation(self, pop_size: int, current_generation_num: int) -> None:
        """
        Runs a single generation of the evolutionary algorithm.
        For M0, this is a stub that simulates work and updates population (placeholder).
        Actual evolutionary operators (selection, crossover, mutation, evaluation)
        will be implemented in later milestones.

        Args:
            pop_size (int): The target population size for this generation,
                            determined by the PID controller.
            current_generation_num (int): The current generation number.
        """
        logger.info(f"Running generation {current_generation_num + 1} with target population size {pop_size}")
        
        # Placeholder: Adjust current self.population to pop_size (e.g., truncate or add random)
        if len(self.population) > pop_size:
            self.population = self.population[:pop_size]
        elif len(self.population) < pop_size:
            # Add random individuals (placeholder)
            for _ in range(pop_size - len(self.population)):
                self.population.append(self._generate_random_test())
        
        # Placeholder: Simulate evolutionary operations
        # In a real implementation, this would involve:
        # 1. _evaluate_population() (if not already done for initial pop)
        # 2. _evolve_generation() -> creates new offspring, combines, selects
        # 3. _update_adaptive_parameters()
        
        # For M0, we just log and prepare for cost simulation
        logger.debug(f"Generation {current_generation_num + 1} stub: population size now {len(self.population)}")
        
        # Simulate some metric improvement (for target_delta_m check)
        # This would come from actual fitness evaluation in later milestones
        self.current_delta_m += random.uniform(0.001, 0.005) * (pop_size / 10.0) # Improvement scales with pop_size
        self.current_delta_m = min(self.current_delta_m, 0.1) # Cap delta_m for simulation
        logger.debug(f"Simulated current_delta_m: {self.current_delta_m:.4f}")


    def evolve(self) -> List[TestIndividual]: # Return type changed
        """
        Main evolution loop, controlled by PID and budget.
        Runs generations until budget is exhausted or target metric delta is met.

        Returns:
            List[TestIndividual]: The list of best individuals found.
                                  For M0, this will be an empty list.
        """
        logger.info(f"Starting AdaptiveEMT.evolve() with budget: CPU {self.budget.cpu_core_min}m, "
                    f"Wall {self.budget.wall_min or 'N/A'}m, Target M' delta {self.budget.target_delta_m or 'N/A'}")

        self._initialize_population() # Uses self.existing_tests_paths
        
        # Generate all mutants for the project once at the beginning of evolve
        # This list will be used by high-fidelity evaluations and as a source for get_hardest_mutants
        logger.info(f"Generating all mutants for project root: {self.code_root}")
        # self.all_project_mutants = self.smart_mutator.generate_mutants_for_project(
        #     target_path=str(self.code_root), # Assuming smart_mutator can take a general path
        #     focus_modules=self.focus_modules # Pass focus modules if available
        # )
        # For M0, SmartMutator.generate_mutants_for_project might not be fully ready or might be slow.
        # Using a placeholder for all_project_mutants for now to avoid breaking the flow.
        self.all_project_mutants = [
            {"id": f"proj_mut_{i}", "file_path": "dummy_src/file.py", "line_number": 20+i,
             "original_code_snippet": "x == y", "mutated_code_snippet": "x != y",
             "status": "unknown", "operator_type": "COMPARISON_REPLACEMENT"}
            for i in range(200) # Simulate 200 project mutants
        ]
        logger.info(f"Generated/loaded {len(self.all_project_mutants)} total project mutants (simulated for M0).")
        
        # current_mutants for a generation might be a subset (e.g., hardest)
        # self.current_mutants = self.get_hardest_mutants() # Get initial set for low-fi
        # This is now self.hardest_mutants_cache, populated by get_hardest_mutants
        if not self.hardest_mutants_cache: # Ensure it's populated if not already
            self.get_hardest_mutants()


        self.cpu_used_total_min = 0.0
        self.wall_time_start = time.monotonic()
        self.current_generation_num = 0
        self.pid.reset_integral() # Reset PID for this run

        # Determine max generations based on a heuristic or keep it open ended by budget
        # For M0, the loop is primarily budget-driven.
        # A very high max_generations can be set if we want budget to be the sole decider.
        max_generations_heuristic = 100 # A practical upper limit for the loop

        while self.current_generation_num < max_generations_heuristic:
            # 1. Check Wall Time Budget (if specified)
            if self.budget.wall_min is not None:
                elapsed_wall_min = (time.monotonic() - self.wall_time_start) / 60.0
                if elapsed_wall_min >= self.budget.wall_min:
                    logger.info(f"Wall time budget ({self.budget.wall_min}m) exceeded. Stopping evolution.")
                    break
            
            # 2. Check CPU Time Budget
            if self.cpu_used_total_min >= self.budget.cpu_core_min:
                logger.info(f"CPU budget ({self.budget.cpu_core_min} core-min) exceeded. Stopping evolution.")
                break

            # 3. Get next population size from PID controller
            #    The Process Variable (pv) for PID could be cpu_used_total_min or current_delta_m
            #    Let's use cpu_used_total_min for now, with setpoint being self.budget.cpu_core_min
            #    The PID's output is population size.
            #    This assumes PID is configured with sp = self.budget.cpu_core_min
            #    A more sophisticated PID might have its setpoint as "remaining budget" or "target metric"
            
            # For M0, let's use a simpler PID interaction:
            # PID's setpoint is the total CPU budget. PV is current CPU used.
            # The PID will try to recommend a pop_size.
            # We need to ensure the PID is configured appropriately by the caller.
            # For this stub, we'll assume self.pid.sp is set to self.budget.cpu_core_min
            
            # The PID controller's `next` method expects the current process variable.
            # If controlling based on CPU usage, pv = self.cpu_used_total_min
            # If controlling based on achieving target_delta_m, pv = self.current_delta_m and sp = self.budget.target_delta_m
            # For M0, let's assume the PID is for CPU budget.
            current_pop_size = self.pid.next(pv=self.cpu_used_total_min)
            
            # Map PID output (population_size) to generations for this run_one_generation call
            # As per user spec: generations approx pop_size / 2
            # This means _run_one_generation is more like "run a chunk of work"
            # For M0, _run_one_generation is just a stub.
            # Let's simplify: _run_one_generation IS one generation.
            
            logger.info(f"Generation {self.current_generation_num + 1}: "
                        f"PID recommended pop_size={current_pop_size}. "
                        f"CPU used so far: {self.cpu_used_total_min:.2f}/{self.budget.cpu_core_min}m.")

            self._run_one_generation(pop_size=current_pop_size, current_generation_num=self.current_generation_num)
            
            # 4. Measure/Simulate cost of the generation
            gen_cpu_cost, _ = self._simulate_generation_cost(current_pop_size) # wall cost not used in loop break yet
            self.cpu_used_total_min += gen_cpu_cost
            
            # 5. Check if target_delta_m is met (if specified)
            if self.budget.target_delta_m is not None and self.current_delta_m >= self.budget.target_delta_m:
                logger.info(f"Target M' delta ({self.budget.target_delta_m}) achieved. Stopping evolution.")
                break
            
            self.current_generation_num += 1
            
            # Placeholder for early stopping based on stagnation (internal to AdaptiveEMT)
            # if self._should_stop_early(self.population): 
            #     logger.info("Internal early stopping triggered due to stagnation.")
            #     break

        logger.info(f"Evolution finished after {self.current_generation_num} generations. "
                    f"Total CPU used: {self.cpu_used_total_min:.2f}m.")
        
        # For M0, return an empty list as per requirement
        return []


    # --- Helper methods from original implementation (may need review/integration later) ---
    # _evaluate_population, _evaluate_individual_fitness_vector, _evolve_generation,
    # _tournament_selection_nsga2, _should_stop_early (needs rework for new budget/PID),
    # _update_adaptive_parameters, _calculate_population_diversity, _calculate_test_similarity,
    # _parse_test_to_individual, _generate_random_test, _load_existing_tests,
    # _test_kills_mutant, _measure_test_speed, _measure_determinism,
    # get_evolution_summary, _find_convergence_generation
    # These are kept for reference but are not actively used or fully integrated in M0.

    def _generate_random_test(self) -> TestIndividual:
        """Generate a random test individual (placeholder)."""
        test_code = "def test_random_generated():\n    assert 1 == random.randint(1, 2)"
        return TestIndividual(
            test_code=test_code,
            assertions=[{'type': 'equality', 'code': 'assert 1 == random.randint(1, 2)', 'target_criticality': 1.0}],
            generation=self.current_generation_num # Use current generation
        )

    # Placeholder for methods that would be part of full NSGA-II cycle, not used in M0 stub
    def _evolve_generation(self, current_population: List[TestIndividual]) -> List[TestIndividual]:
        logger.debug("Stub _evolve_generation called.")
        # This would involve selection, crossover, mutation
        # For M0, just return a slightly modified version or the same population
        # to ensure the loop can proceed if this were called.
        # The current M0 `evolve` loop calls `_run_one_generation` which handles population.
        return current_population 

    def _evaluate_population(self) -> None:
        logger.debug("Stub _evaluate_population called.")
        # This would calculate fitness, rank, crowding distance for all individuals
        # For M0, this is not fully implemented.
        for ind in self.population:
            if not hasattr(ind, 'fitness_values') or ind.fitness_values is None:
                ind.fitness_values = FitnessVector() # Default
            if not hasattr(ind, 'pareto_rank'):
                ind.pareto_rank = 0
            if not hasattr(ind, 'crowding_distance'):
                ind.crowding_distance = 0.0
        pass

    def _update_adaptive_parameters(self, current_population: List[TestIndividual]):
        logger.debug("Stub _update_adaptive_parameters called.")
        # This would adjust mutation_rate, etc.
        pass
        
    def _should_stop_early(self, current_population: List[TestIndividual]) -> bool:
        # This internal early stopping (stagnation) is different from budget/target_delta
        # For M0, we can disable it or make it very lenient.
        # The main evolve loop handles budget/target_delta stopping.
        # This could be used if budget is very large and we want to stop if no progress.
        # For now, let's make it not stop early internally.
        # self.stagnation_counter +=1
        # return self.stagnation_counter > self.early_stopping_patience
        return False # Disable internal early stopping for M0

    def _calculate_population_diversity(self) -> float:
        """Calculate population diversity metric (placeholder)."""
        if len(self.population) < 2: return 1.0
        # Simplified: count unique test code strings
        unique_codes = {ind.test_code for ind in self.population}
        return len(unique_codes) / len(self.population) if self.population else 0.0

    def _extract_features_for_gp(self, individual: TestIndividual, f1_score: Optional[float] = None) -> np.ndarray:
        """
        Extracts features from a TestIndividual to be used as input (X) for the GP.
        For the model f2(x) = rho*f1(x) + delta(x), x are features of the individual.
        
        Args:
            individual: The TestIndividual object.
            f1_score: The low-fidelity score, can be one of the features.

        Returns:
            A numpy array representing the features. Shape (1, n_features).
        """
        # Placeholder: using f1_score (if available) and number of assertions.
        # This needs to be a fixed-size vector and carefully chosen.
        # For initial implementation, let's use a very simple feature set.
        # If f1_score is not yet computed for this individual (e.g. predicting for a new candidate),
        # it might not be available as a feature for delta(x) if delta is a function of x, not f1(x).
        # The model is delta(x), so features should come from x (the individual).
        
        num_assertions = len(individual.assertions) if individual.assertions else 0
        test_code_length = len(individual.test_code) if individual.test_code else 0
        
        # Example features: [num_assertions, test_code_length]
        # Ensure this is consistent with what the GP expects.
        features = np.array([float(num_assertions), float(test_code_length)])
        return features.reshape(1, -1)


    def _update_gp_model(self) -> None:
        """
        Updates the hierarchical Gaussian Process model f2(x) = rho*f1(x) + delta(x).
        This method should be called when new (features_x, f1_score, f2_score) tuples are available
        in self.multi_fidelity_training_data.
        """
        # Require a minimum number of data points that have *both* f1 and f2 scores.
        # self.multi_fidelity_training_data stores (individual_features_array, f1_score, f2_score)
        if len(self.multi_fidelity_training_data) < 5: # Increased min points for more stable GP
            logger.info(f"Not enough multi-fidelity data points ({len(self.multi_fidelity_training_data)}) to train GP model robustly. Need at least 5.")
            self.gp_model_delta = None
            return

        X_features_list = [data_point[0].flatten() for data_point in self.multi_fidelity_training_data] # Ensure features are 1D for vstack
        f1_scores = np.array([data_point[1] for data_point in self.multi_fidelity_training_data])
        f2_scores = np.array([data_point[2] for data_point in self.multi_fidelity_training_data])

        X_gp_input = np.array(X_features_list) # Shape: (n_samples, n_features_for_delta_gp)
        
        # 1. Estimate rho using linear regression: f2_scores = rho * f1_scores + intercept
        # The intercept can be absorbed by the GP's mean function for delta.
        # Or, f2_scores - intercept = rho * f1_scores
        # Simpler: rho = (f1^T f1)^-1 f1^T f2, assuming f1 is a column vector.
        # Reshape f1_scores to be a column vector for LinearRegression
        f1_reshaped = f1_scores.reshape(-1, 1)
        
        try:
            # Regression of f2 on f1 to find rho
            # (f2_i - delta_i) = rho * f1_i.  If E[delta_i] = 0, then f2_i approx rho * f1_i
            # We can regress f2 on f1. The coefficient will be our rho.
            rho_estimator = LinearRegression(fit_intercept=False) # delta(x) will handle the mean/intercept
            rho_estimator.fit(f1_reshaped, f2_scores)
            estimated_rho = rho_estimator.coef_[0]
            
            # Clip rho to a reasonable range, e.g., [0.1, 3.0], to prevent extreme values from sparse data.
            # The Beta(2,2) prior for rho has mean 0.5, variance 0.05. Most mass between 0 and 1.
            self.gp_rho = np.clip(estimated_rho, 0.1, 2.0)
            logger.info(f"Updated GP rho estimate: {self.gp_rho:.4f} (raw: {estimated_rho:.4f})")
        except Exception as e:
            logger.warning(f"Failed to estimate rho using Linear Regression: {e}. Using previous/default: {self.gp_rho:.4f}")
            # If estimation fails, stick to the current self.gp_rho (e.g. prior mean)

        # 2. Calculate residuals for delta(x): Y_delta = f2_scores - self.gp_rho * f1_scores
        Y_delta = f2_scores - self.gp_rho * f1_scores

        # 3. Train GP model for delta(x) using X_gp_input (features of x) and Y_delta
        if self.gp_model_delta is None:
            self.gp_model_delta = GaussianProcessRegressor(kernel=self.gp_kernel,
                                                         alpha=1e-5, # Small noise term for stability
                                                         n_restarts_optimizer=10,
                                                         random_state=42)
        
        try:
            self.gp_model_delta.fit(X_gp_input, Y_delta)
            logger.info(f"GP model for delta(x) updated with {X_gp_input.shape[0]} points. Kernel after fit: {self.gp_model_delta.kernel_}")
            logger.debug(f"GP Log-Marginal-Likelihood: {self.gp_model_delta.log_marginal_likelihood_value_:.3f}")
        except Exception as e:
            logger.error(f"Failed to fit GP model for delta(x): {e}")
            self.gp_model_delta = None # Invalidate model on error

    def predict_f2_with_gp(self, individual: TestIndividual, f1_score: float) -> Tuple[float, float]:
        """
        Predicts the high-fidelity score f2(x) and its variance using the GP model.
        f2_pred(x) = rho * f1(x) + delta_pred(x)
        Var(f2_pred(x)) approx Var(delta_pred(x)) (assuming rho and f1(x) are 'fixed' for this prediction step,
                                                or if rho is a sample from its posterior, variance would propagate).
                                                For simplicity, we use Var(delta_pred(x)).
        """
        if self.gp_model_delta is None or not hasattr(self.gp_model_delta, "kernel_"): # Check if model is fitted
            logger.warning("GP model for delta not available or not fitted. Returning f1_score*rho as f2 prediction with high uncertainty.")
            return self.gp_rho * f1_score, 1.0 # Default high variance (e.g. 1.0)
        
        individual_features_X = self._extract_features_for_gp(individual, f1_score) # Shape (1, n_features)
        
        try:
            delta_pred_mean, delta_pred_std = self.gp_model_delta.predict(individual_features_X, return_std=True)
            
            f2_predicted_mean = self.gp_rho * f1_score + delta_pred_mean[0]
            # Ensure variance is non-negative
            f2_predicted_variance = max(0.0, delta_pred_std[0]**2)
            
            logger.debug(f"GP Prediction: f1={f1_score:.3f}, rho={self.gp_rho:.3f}, delta_mean={delta_pred_mean[0]:.3f} => f2_pred={f2_predicted_mean:.3f}, f2_std_dev={np.sqrt(f2_predicted_variance):.3f}")
            return f2_predicted_mean, f2_predicted_variance
        except Exception as e:
            logger.error(f"Error during GP prediction for f2: {e}")
            return self.gp_rho * f1_score, 1.0 # Fallback on error

    def _calculate_mf_ei(self, individual: TestIndividual, f1_score: float, best_f2_observed: float) -> float:
        """
        Calculates a simplified Multi-Fidelity Expected Improvement for an individual.
        Assumes cost of high-fidelity evaluation is uniform for now.
        Args:
            individual: The test individual.
            f1_score: The observed low-fidelity score for this individual.
            best_f2_observed: The best high-fidelity score observed so far in the population.
        Returns:
            The MF-EI value.
        """
        if self.gp_model_delta is None:
            return 0.0 # Cannot calculate EI without a GP model

        mean_f2_pred, var_f2_pred = self.predict_f2_with_gp(individual, f1_score)
        std_f2_pred = np.sqrt(max(1e-9, var_f2_pred)) # Ensure std_dev is non-zero and positive

        # Standard EI formula components
        # For maximization, improvement = mean_f2_pred - best_f2_observed
        # We can add a small exploration parameter xi, e.g., 0.01
        xi = 0.01
        improvement = mean_f2_pred - best_f2_observed - xi
        
        if std_f2_pred < 1e-9: # Avoid division by zero if std is effectively zero
            # If no uncertainty, EI is positive only if mean_f2_pred is better than best_f2_observed + xi
            return max(0, improvement)

        Z = improvement / std_f2_pred
        
        # Phi and phi are CDF and PDF of standard normal distribution
        from scipy.stats import norm # Import locally or at top of file
        ei = improvement * norm.cdf(Z) + std_f2_pred * norm.pdf(Z)
        
        # For MF-EI, divide by cost. Assuming cost is 1 for now.
        # cost_high_fidelity = 1.0
        # mf_ei = ei / cost_high_fidelity
        return max(0, ei) # EI should be non-negative

    def _select_individuals_for_high_fidelity(self,
                                             candidates: List[TestIndividual],
                                             low_fidelity_scores: List[float],
                                             num_to_select: int) -> List[Tuple[TestIndividual, float]]:
        """
        Selects a subset of candidate individuals for high-fidelity evaluation using MF-EI.
        
        Args:
            candidates: A list of TestIndividuals that have been evaluated with low-fidelity.
            low_fidelity_scores: A list of corresponding f1_scores for the candidates.
            num_to_select: The number of individuals to select for high-fidelity evaluation.

        Returns:
            A list of (TestIndividual, f1_score) tuples for selected individuals.
        """
        if not candidates or self.gp_model_delta is None:
            logger.warning("Cannot select for high-fidelity: no candidates or GP model not ready.")
            # Fallback: select randomly or based on best f1 if no GP
            if candidates and num_to_select > 0:
                selected_indices = random.sample(range(len(candidates)), min(num_to_select, len(candidates)))
                return [(candidates[i], low_fidelity_scores[i]) for i in selected_indices]
            return []

        # Find the best f2 score observed so far from self.multi_fidelity_training_data
        if not self.multi_fidelity_training_data:
            best_f2_observed = -float('inf') # No observations yet
        else:
            best_f2_observed = max(data_point[2] for data_point in self.multi_fidelity_training_data)

        mf_ei_values = []
        for i, individual in enumerate(candidates):
            f1_score = low_fidelity_scores[i]
            ei = self._calculate_mf_ei(individual, f1_score, best_f2_observed)
            mf_ei_values.append((ei, i)) # Store EI and original index

        # Sort by EI in descending order
        mf_ei_values.sort(key=lambda x: x[0], reverse=True)
        
        selected_for_hf = []
        for ei_val, index in mf_ei_values[:num_to_select]:
            selected_for_hf.append((candidates[index], low_fidelity_scores[index]))
            logger.debug(f"Selected individual (index {index}) for HF eval with MF-EI: {ei_val:.4f}")
            
        return selected_for_hf
